=== CMD varas ===
enable_debug: true
enable_stdout: false
printprogress: true
skip_run: false
config_path: /home/leoyu/Cebinae/ns/configs/thresh.json
result_dir: tmp_index/thresh/cebinae-100/
sack: true
recovery: ns3::TcpClassicRecovery
app_packet_size: 1440
delackcount: 1
seed: 2022
run: 1205
tracing_period_us: 1000000
progress_interval_ms: 1000
sim_seconds: 100
app_seconds_start: 1
app_seconds_end: 100
transport_prot0: ns3::TcpNewReno
transport_prot1: ns3::TcpCubic
transport_prot2: ns3::TcpCubic
transport_prot3: ns3::TcpCubic
transport_prot4: ns3::TcpCubic
transport_prot5: ns3::TcpCubic
transport_prot6: ns3::TcpCubic
transport_prot7: ns3::TcpCubic
transport_prot8: ns3::TcpCubic
bottleneck_bw: 100Mbps
bottleneck_delay: 20ms
leaf_bw0: 10000Mbps
leaf_bw1: 10000Mbps
leaf_bw2: 0Mbps
leaf_bw3: 0Mbps
leaf_bw4: 0Mbps
leaf_bw5: 0Mbps
leaf_bw6: 0Mbps
leaf_bw7: 0Mbps
leaf_bw8: 0Mbps
leaf_delay0: 2.5ms
leaf_delay1: 0.1ms
leaf_delay2: 1ms
leaf_delay3: 1ms
leaf_delay4: 1ms
leaf_delay5: 1ms
leaf_delay6: 1ms
leaf_delay7: 1ms
leaf_delay8: 1ms
app_bw0: 100Mbps
app_bw1: 100Mbps
app_bw2: 0Mbps
app_bw3: 0Mbps
app_bw4: 0Mbps
app_bw5: 0Mbps
app_bw6: 0Mbps
app_bw7: 0Mbps
app_bw8: 0Mbps
switch_total_bufsize: 420p
switch_netdev_size: 1p
server_netdev_size: 100p
queuedisc_type: CebinaeQueueDisc
num_cca0: 16
num_cca1: 1
num_cca2: 0
num_cca3: 0
num_cca4: 0
num_cca5: 0
num_cca6: 0
num_cca7: 0
num_cca8: 0
num_leaf: 17
======
--- Configured CebinaeQueueDisc ---
dt: +6.71089e+07ns
vdt: +1ns
l: +100000ns
p: 1
tau: 1
delta_port: 1
delta_flow: 1
------
num_tracing_periods: 100
=== Ipv4 addresses ===
--- leftleaf_ifc ---
0 1.1.1.1
1 1.1.2.1
2 1.1.3.1
3 1.1.4.1
4 1.1.5.1
5 1.1.6.1
6 1.1.7.1
7 1.1.8.1
8 1.1.9.1
9 1.1.10.1
10 1.1.11.1
11 1.1.12.1
12 1.1.13.1
13 1.1.14.1
14 1.1.15.1
15 1.1.16.1
16 1.1.17.1
--- leftrouter_ifc ---
0 1.1.1.2
1 1.1.2.2
2 1.1.3.2
3 1.1.4.2
4 1.1.5.2
5 1.1.6.2
6 1.1.7.2
7 1.1.8.2
8 1.1.9.2
9 1.1.10.2
10 1.1.11.2
11 1.1.12.2
12 1.1.13.2
13 1.1.14.2
14 1.1.15.2
15 1.1.16.2
16 1.1.17.2
--- rightleaf_ifc ---
0 100.1.1.1
1 100.1.2.1
2 100.1.3.1
3 100.1.4.1
4 100.1.5.1
5 100.1.6.1
6 100.1.7.1
7 100.1.8.1
8 100.1.9.1
9 100.1.10.1
10 100.1.11.1
11 100.1.12.1
12 100.1.13.1
13 100.1.14.1
14 100.1.15.1
15 100.1.16.1
16 100.1.17.1
--- rightrouter_ifc ---
0 100.1.1.2
1 100.1.2.2
2 100.1.3.2
3 100.1.4.2
4 100.1.5.2
5 100.1.6.2
6 100.1.7.2
7 100.1.8.2
8 100.1.9.2
9 100.1.10.2
10 100.1.11.2
11 100.1.12.2
12 100.1.13.2
13 100.1.14.2
14 100.1.15.2
15 100.1.16.2
16 100.1.17.2
--- router_ifc ---
0 200.1.1.1
1 200.1.1.2
=== avg_tpt_bottleneck[*] ===
0 17867.636
1 17867.636
2 17867.636
3 17867.636
4 17867.636
5 17867.636
6 17626.182
7 17626.182
8 17626.182
9 17626.182
10 17626.182
11 17384.727
12 17384.727
13 17384.727
14 17143.273
15 17143.273
16 18350.545
Avg. Throughput [bps]: 300128.000
avg_jfi_bottleneck [computed]: 1.000
=== avg_tpt_app[*] ===
0 17221.818
1 17221.818
2 17221.818
3 17221.818
4 17221.818
5 17221.818
6 16989.091
7 16989.091
8 16989.091
9 16989.091
10 16989.091
11 16756.364
12 16756.364
13 16756.364
14 16523.636
15 16523.636
16 17687.273
Avg. Goodput [bps]: 289280.000
avg_jfi_app [computed]: 1.000
# of RTT samples for source 0: 24
Avg. RTT for source 0: 50414933.792ns
# of RTT samples for source 1: 28
Avg. RTT for source 1: 50682212.821ns
# of RTT samples for source 2: 30
Avg. RTT for source 2: 50941535.733ns
# of RTT samples for source 3: 29
Avg. RTT for source 3: 51424963.793ns
# of RTT samples for source 4: 30
Avg. RTT for source 4: 51716163.333ns
# of RTT samples for source 5: 30
Avg. RTT for source 5: 52143140.933ns
# of RTT samples for source 6: 29
Avg. RTT for source 6: 52627419.138ns
# of RTT samples for source 7: 29
Avg. RTT for source 7: 52940723.793ns
# of RTT samples for source 8: 29
Avg. RTT for source 8: 53386754.414ns
# of RTT samples for source 9: 29
Avg. RTT for source 9: 53751785.552ns
# of RTT samples for source 10: 30
Avg. RTT for source 10: 54043141.233ns
# of RTT samples for source 11: 29
Avg. RTT for source 11: 54613421.862ns
# of RTT samples for source 12: 29
Avg. RTT for source 12: 54928657.414ns
# of RTT samples for source 13: 29
Avg. RTT for source 13: 55328262.000ns
# of RTT samples for source 14: 29
Avg. RTT for source 14: 55636384.931ns
# of RTT samples for source 15: 29
Avg. RTT for source 15: 56048452.621ns
# of RTT samples for source 16: 32
Avg. RTT for source 16: 40597886.188ns
====== Number of packets sent ======
MySource 0:859375
MySource 1:859375
MySource 2:859375
MySource 3:859375
MySource 4:859375
MySource 5:859375
MySource 6:859375
MySource 7:859375
MySource 8:859375
MySource 9:859375
MySource 10:859375
MySource 11:859375
MySource 12:859375
MySource 13:859375
MySource 14:859375
MySource 15:859375
MySource 16:859375
====== Number of packets at bottleneck link ======
Source 15: 145
Source 14: 145
Source 13: 145
Source 12: 145
Source 16: 155
Source 3: 149
Source 0: 151
Source 1: 151
Source 2: 151
Source 4: 149
Source 5: 149
Source 6: 147
Source 7: 147
Source 8: 147
Source 9: 147
Source 10: 147
Source 11: 145
====== CebinaeQueueDisc digest ======
--- Validate the effective CebinaeQueueDisc params ---
m_debug: true
m_maxSize: 420p
GetInternalQueue(0)->GetMaxSize(): 420p
GetInternalQueue(1)->GetMaxSize(): 420p
dT: +6.71089e+07ns
vdT: +1ns
L: +100000ns
P: 1
tau: 1
delta_port: 1
delta_top: 1
m_pool: true
m_bps: 100000000bps
--- Validate CebinaeQueueDisc initial states ---
m_headq: 0
m_neg_headq: 1
m_vb: 67108864
------
m_arrived_pkts: 6055
m_lbf_past_head_pkts: 2536
m_lbf_past_tail_pkts: 13
m_lbf_drop_pkts: 3506
m_enqueue_drop_pkts[0]: 0
m_enqueue_drop_pkts[1]: 0
m_cebinae_dequeued_succeeded: 2549
m_num_p: 1489
m_num_bottleneck_p: 358
m_num_non_bottleneck_p: 1131
m_num_rotated: 1490
--- FlowBottleneckDetector ---
m_num_gettopflows: 358
m_num_slot_pow2: 11
m_num_slot: 2048
m_hash2mysourceid.size(): 2048
m_hash2bytecount.size(): 2048
m_sourceidtag2toptimes:
2: 94
15: 94
13: 94
10: 94
14: 94
1: 94
16: 96
3: 94
9: 94
6: 94
7: 94
11: 94
5: 94
0: 94
12: 94
8: 94
4: 94
sourceids_wo_slots (during some round(s) due to 5-tuple hash collision):
------

=== Completion time [s]: 6.186===
